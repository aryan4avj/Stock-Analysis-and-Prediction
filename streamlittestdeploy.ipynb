{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of streamlit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AryanWadhwa05/Stock-Analysis-and-Prediction/blob/main/streamlittestdeploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrgVU_YHFcSJ"
      },
      "source": [
        "#@title Run this cell to load some data\n",
        "!pip install streamlit\n",
        "!pip install pyngrok \n",
        "!pip install yfinance\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import streamlit as st\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas_datareader import data as pdr\n",
        "import plotly.express as px\n",
        "import re\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "%matplotlib inline\n",
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize']=20,10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,Dropout,Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# %%writefile app.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZeLRsY-FXsY",
        "outputId": "5feeb598-a353-435c-bbf3-3e1b34ceec4b"
      },
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas_datareader import data as pdr\n",
        "import plotly.express as px\n",
        "import re\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "\n",
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize']=20,10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,Dropout,Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# download dataframe\n",
        "st.title(\"Stock Market Analysis\")\n",
        "\n",
        "#sidebar\n",
        "st.sidebar.title(\"Stocks\")\n",
        "\n",
        "st.sidebar.subheader(\"Stock Search\")\n",
        "\n",
        "stock_search_test = st.sidebar.text_input('Stock Search')\n",
        "display_cols = st.sidebar.multiselect('Display Data', [\"Close\",\"Adj Close\",\"Low\",\"Open\",\"High\",\"Volume\"],default = \"High\")\n",
        "graph_type = st.sidebar.selectbox('Graph Type', [\"Line\",\"Bar\",\"Vega Lite\",\"AltAir\",\"High\",\"Volume\"])\n",
        "\n",
        "start_date = st.sidebar.date_input('Start Date')\n",
        "end_date = st.sidebar.date_input('End Date')\n",
        "\n",
        "yf.pdr_override()\n",
        "tickers = \"\"\n",
        "\n",
        "tickers = stock_search_test.replace(\",\",\" \")\n",
        "\n",
        "data = yf.download(tickers, start=start_date, end=end_date)\n",
        "\n",
        "dataframe = data[display_cols]\n",
        "dataframe.reset_index(level=0, inplace=True)\n",
        "\n",
        "# dataframe.replace('^\\b+', '', regex=True, inplace=True)\n",
        "st.write(dataframe)\n",
        "\n",
        "plt.plot(dataframe[\"Date\"],dataframe[\"High\"])\n",
        "# plt.legend(dataframe[\"High\"])\n",
        "plt.ylabel(\"Dollars\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.draw()\n",
        "\n",
        "st.pyplot(plt)\n",
        "\n",
        "# # machine learning starts\n",
        "cf=dataframe\n",
        "\n",
        "# cf[\"Date\"]=pd.to_datetime(cf.Date,format=\"%Y-%m-%d\")\n",
        "cf.index=cf['Date']\n",
        "\n",
        "# st.write(dataframe)\n",
        "\n",
        "# plt.figure(figsize=(16,8))\n",
        "# plt.plot(cf[\"Close\"],label='Close Price history')\n",
        "\n",
        "data=cf.sort_index(ascending=True,axis=0)\n",
        "new_dataset=pd.DataFrame(index=range(0,len(cf)),columns=['Date',\"High\"])\n",
        "\n",
        "for i in range(0,len(data)):\n",
        "    new_dataset[\"Date\"][i]=data['Date'][i]\n",
        "    new_dataset[display_cols[0]][i]=data[display_cols[0]][i]\n",
        "\n",
        "new_dataset[\"Date\"].apply('str')\n",
        "final_dataset=new_dataset.values\n",
        "\n",
        "train_data=[]\n",
        "valid_data=[]\n",
        "\n",
        "#splitting the dataset\n",
        "train_data_number = int((len(final_dataset)*0.8))\n",
        "train_data=final_dataset[0:train_data_number,:]\n",
        "valid_data=final_dataset[train_data_number:,:]\n",
        "\n",
        "new_dataset.index=new_dataset.Date\n",
        "new_dataset.drop(\"Date\",axis=1,inplace=True)\n",
        "\n",
        "#Feature Scaling\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data=scaler.fit_transform(new_dataset)\n",
        "\n",
        "# new_dataset.reset_index(level=0, inplace=True)\n",
        "# new_dataset[\"High\"] = scaled_data\n",
        "\n",
        "# st.write(new_dataset)\n",
        "\n",
        "x_train_data,y_train_data=[],[]\n",
        "\n",
        "for i in range(60,len(train_data)):\n",
        "    x_train_data.append(scaled_data[i-60:i,0])\n",
        "    y_train_data.append(scaled_data[i,0])\n",
        "    \n",
        "x_train_data,y_train_data=np.array(x_train_data),np.array(y_train_data) #(len(data),60))\n",
        "\n",
        "x_train_data=np.reshape(x_train_data,(x_train_data.shape[0],x_train_data.shape[1],1)) #(len(data), 60, 1)\n",
        "\n",
        "# lstm architecture\n",
        "lstm_model=Sequential()\n",
        "lstm_model.add(LSTM(units=50,return_sequences=True,input_shape=(x_train_data.shape[1],1)))\n",
        "lstm_model.add(LSTM(units=50))\n",
        "lstm_model.add(Dense(1))\n",
        "\n",
        "inputs_data=new_dataset[len(new_dataset)-len(valid_data)-60:].values\n",
        "inputs_data=inputs_data.reshape(-1,1)\n",
        "inputs_data=scaler.transform(inputs_data)\n",
        "\n",
        "lstm_model.compile(loss='mean_squared_error',optimizer='adam')\n",
        "lstm_model.fit(x_train_data,y_train_data,epochs=25,batch_size=20,verbose=2)\n",
        "\n",
        "#Testing\n",
        "X_test=[]\n",
        "for i in range(60,inputs_data.shape[0]):\n",
        "    X_test.append(inputs_data[i-60:i,0])\n",
        "X_test=np.array(X_test)\n",
        "\n",
        "X_test=np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
        "predicted_closing_price=lstm_model.predict(X_test)\n",
        "predicted_closing_price=scaler.inverse_transform(predicted_closing_price)\n",
        "\n",
        "train_data=new_dataset[:train_data_number]\n",
        "valid_data=new_dataset[train_data_number:]\n",
        "\n",
        "valid_data['Predictions']=predicted_closing_price\n",
        "plt.plot(train_data[\"High\"])\n",
        "plt.plot(valid_data[['High',\"Predictions\"]])\n",
        "st.pyplot(plt)\n",
        "\n",
        "st.write(valid_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unKPV9GQFfeS",
        "outputId": "8da81a33-bdd9-47d4-9fd4-6a5ae5804017"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "#Publish Web App (Run this again whenever you make changes)\n",
        "public_url = ngrok.connect(port='80')\n",
        "print (public_url)\n",
        "!streamlit run --server.port 80 app.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-25 02:27:23.258 INFO    pyngrok.ngrok: Opening tunnel named: http-80-0651c474-47b0-4fa4-a5df-3267be3658a0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-25 02:27:28.717 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:28+0000 lvl=info msg=\"no configuration paths supplied\"\n",
            "2021-10-25 02:27:28.719 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:28+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.ngrok2/ngrok.yml\n",
            "2021-10-25 02:27:28.721 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:28+0000 lvl=info msg=\"open config file\" path=/root/.ngrok2/ngrok.yml err=nil\n",
            "2021-10-25 02:27:28.722 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:28+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040\n",
            "2021-10-25 02:27:28.946 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:28+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "2021-10-25 02:27:28.947 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:28+0000 lvl=info msg=\"client session established\" obj=csess id=4c36c91bffe3\n",
            "2021-10-25 02:27:28.955 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:28+0000 lvl=info msg=start pg=/api/tunnels id=9af2b7b9c0f8bd42\n",
            "2021-10-25 02:27:28.956 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:28+0000 lvl=info msg=end pg=/api/tunnels id=9af2b7b9c0f8bd42 status=200 dur=508.249µs\n",
            "2021-10-25 02:27:28.958 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:28+0000 lvl=info msg=start pg=/api/tunnels id=5501fac78ccee4c9\n",
            "2021-10-25 02:27:28.960 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:28+0000 lvl=info msg=end pg=/api/tunnels id=5501fac78ccee4c9 status=200 dur=109.815µs\n",
            "2021-10-25 02:27:28.961 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:28+0000 lvl=info msg=start pg=/api/tunnels id=f09fefce3660cc41\n",
            "2021-10-25 02:27:29.093 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:29+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=\"http-80-0651c474-47b0-4fa4-a5df-3267be3658a0 (http)\" addr=http://localhost:80 url=http://ffeb-34-125-79-76.ngrok.io\n",
            "2021-10-25 02:27:29.095 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:29+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=http-80-0651c474-47b0-4fa4-a5df-3267be3658a0 addr=http://localhost:80 url=https://ffeb-34-125-79-76.ngrok.io\n",
            "2021-10-25 02:27:29.097 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:29+0000 lvl=info msg=end pg=/api/tunnels id=f09fefce3660cc41 status=201 dur=138.392681ms\n",
            "2021-10-25 02:27:29.099 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:29+0000 lvl=info msg=start pg=\"/api/tunnels/http-80-0651c474-47b0-4fa4-a5df-3267be3658a0 (http)\" id=b3ec15ad2072a109\n",
            "2021-10-25 02:27:29.101 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:29+0000 lvl=info msg=end pg=\"/api/tunnels/http-80-0651c474-47b0-4fa4-a5df-3267be3658a0 (http)\" id=b3ec15ad2072a109 status=200 dur=1.904966ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"http://ffeb-34-125-79-76.ngrok.io\" -> \"http://localhost:80\"\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:80\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.79.76:80\u001b[0m\n",
            "\u001b[0m\n",
            "[*********************100%***********************]  0 of 0 completed\n",
            "2021-10-25 02:27:33.311 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/yfinance/multi.py\", line 126, in download\n",
            "    keys=shared._DFS.keys())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\", line 284, in concat\n",
            "    sort=sort,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\", line 331, in __init__\n",
            "    raise ValueError(\"No objects to concatenate\")\n",
            "ValueError: No objects to concatenate\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/script_runner.py\", line 354, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 39, in <module>\n",
            "    data = yf.download(tickers, start=start_date, end=end_date)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/yfinance/multi.py\", line 130, in download\n",
            "    keys=shared._DFS.keys())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\", line 284, in concat\n",
            "    sort=sort,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\", line 331, in __init__\n",
            "    raise ValueError(\"No objects to concatenate\")\n",
            "ValueError: No objects to concatenate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-25 02:27:35.715 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:35+0000 lvl=info msg=\"join connections\" obj=join id=18b2f94fcb0a l=127.0.0.1:80 r=122.177.74.239:27486\n",
            "2021-10-25 02:27:36.189 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:36+0000 lvl=info msg=\"join connections\" obj=join id=d3993b1f610f l=127.0.0.1:80 r=122.177.74.239:32081\n",
            "2021-10-25 02:27:40.885 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:40+0000 lvl=info msg=\"join connections\" obj=join id=2ed3f810dc74 l=127.0.0.1:80 r=122.177.74.239:7222\n",
            "2021-10-25 02:27:41.791 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:41+0000 lvl=info msg=\"join connections\" obj=join id=6ef299f73893 l=127.0.0.1:80 r=122.177.74.239:27486\n",
            "2021-10-25 02:27:41.826 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:41+0000 lvl=info msg=\"join connections\" obj=join id=3288948723dc l=127.0.0.1:80 r=122.177.74.239:19576\n",
            "2021-10-25 02:27:42.124 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:42+0000 lvl=info msg=\"join connections\" obj=join id=18ccd238a10f l=127.0.0.1:80 r=122.177.74.239:32081\n",
            "2021-10-25 02:27:42.126 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:42+0000 lvl=info msg=\"join connections\" obj=join id=9381a1281aa2 l=127.0.0.1:80 r=122.177.74.239:26330\n",
            "2021-10-25 02:27:42.146 INFO    pyngrok.process.ngrok: t=2021-10-25T02:27:42+0000 lvl=info msg=\"join connections\" obj=join id=3c4cd2640327 l=127.0.0.1:80 r=122.177.74.239:27486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  0 of 0 completed\n",
            "2021-10-25 02:39:21.326 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/yfinance/multi.py\", line 126, in download\n",
            "    keys=shared._DFS.keys())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\", line 284, in concat\n",
            "    sort=sort,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\", line 331, in __init__\n",
            "    raise ValueError(\"No objects to concatenate\")\n",
            "ValueError: No objects to concatenate\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/script_runner.py\", line 354, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 39, in <module>\n",
            "    data = yf.download(tickers, start=start_date, end=end_date)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/yfinance/multi.py\", line 130, in download\n",
            "    keys=shared._DFS.keys())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\", line 284, in concat\n",
            "    sort=sort,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\", line 331, in __init__\n",
            "    raise ValueError(\"No objects to concatenate\")\n",
            "ValueError: No objects to concatenate\n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "\n",
            "1 Failed download:\n",
            "- FB: No data found for this date range, symbol may be delisted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-25 02:39:28.714 INFO    pyngrok.process.ngrok: t=2021-10-25T02:39:28+0000 lvl=info msg=\"join connections\" obj=join id=fa6ed45359b4 l=127.0.0.1:80 r=122.177.74.239:6781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-25 02:39:29.201 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/script_runner.py\", line 354, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 89, in <module>\n",
            "    scaled_data=scaler.fit_transform(new_dataset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 571, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 339, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 373, in partial_fit\n",
            "    force_all_finite=\"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 586, in check_array\n",
            "    context))\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-25 02:39:29.676 INFO    pyngrok.process.ngrok: t=2021-10-25T02:39:29+0000 lvl=info msg=\"join connections\" obj=join id=468e1e37e6bd l=127.0.0.1:80 r=122.177.74.239:4834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-25 02:39:41.551 NumExpr defaulting to 2 threads.\n",
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "2021-10-25 02:39:42.888 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/script_runner.py\", line 354, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 97, in <module>\n",
            "    x_train_data.append(scaled_data[i-60:i,0])\n",
            "NameError: name 'x_train_data' is not defined\n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "2021-10-25 02:41:05.275222: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-10-25 02:41:05.275340: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (8a1f5a1b0687): /proc/driver/nvidia/version does not exist\n",
            "2021-10-25 02:41:05.981400: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "Epoch 1/25\n",
            "7/7 - 3s - loss: 0.1916\n",
            "Epoch 2/25\n",
            "7/7 - 0s - loss: 0.0299\n",
            "Epoch 3/25\n",
            "7/7 - 0s - loss: 0.0104\n",
            "Epoch 4/25\n",
            "7/7 - 0s - loss: 0.0147\n",
            "Epoch 5/25\n",
            "7/7 - 0s - loss: 0.0073\n",
            "Epoch 6/25\n",
            "7/7 - 0s - loss: 0.0071\n",
            "Epoch 7/25\n",
            "7/7 - 0s - loss: 0.0058\n",
            "Epoch 8/25\n",
            "7/7 - 0s - loss: 0.0053\n",
            "Epoch 9/25\n",
            "7/7 - 0s - loss: 0.0051\n",
            "Epoch 10/25\n",
            "7/7 - 0s - loss: 0.0048\n",
            "Epoch 11/25\n",
            "7/7 - 0s - loss: 0.0048\n",
            "Epoch 12/25\n",
            "7/7 - 0s - loss: 0.0048\n",
            "Epoch 13/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 14/25\n",
            "7/7 - 0s - loss: 0.0049\n",
            "Epoch 15/25\n",
            "7/7 - 0s - loss: 0.0048\n",
            "Epoch 16/25\n",
            "7/7 - 0s - loss: 0.0048\n",
            "Epoch 17/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 18/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 19/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 20/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 21/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 22/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 23/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 24/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 25/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "2021-10-25 02:41:17.178 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/script_runner.py\", line 354, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 128, in <module>\n",
            "    train_data=new_dataset[:train_number]\n",
            "NameError: name 'train_number' is not defined\n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/25\n",
            "7/7 - 3s - loss: 0.2050\n",
            "Epoch 2/25\n",
            "7/7 - 0s - loss: 0.0257\n",
            "Epoch 3/25\n",
            "7/7 - 0s - loss: 0.0104\n",
            "Epoch 4/25\n",
            "7/7 - 0s - loss: 0.0135\n",
            "Epoch 5/25\n",
            "7/7 - 0s - loss: 0.0066\n",
            "Epoch 6/25\n",
            "7/7 - 0s - loss: 0.0071\n",
            "Epoch 7/25\n",
            "7/7 - 0s - loss: 0.0056\n",
            "Epoch 8/25\n",
            "7/7 - 0s - loss: 0.0052\n",
            "Epoch 9/25\n",
            "7/7 - 0s - loss: 0.0051\n",
            "Epoch 10/25\n",
            "7/7 - 0s - loss: 0.0050\n",
            "Epoch 11/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 12/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 13/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 14/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 15/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 16/25\n",
            "7/7 - 0s - loss: 0.0045\n",
            "Epoch 17/25\n",
            "7/7 - 0s - loss: 0.0045\n",
            "Epoch 18/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 19/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 20/25\n",
            "7/7 - 0s - loss: 0.0049\n",
            "Epoch 21/25\n",
            "7/7 - 0s - loss: 0.0044\n",
            "Epoch 22/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 23/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 24/25\n",
            "7/7 - 0s - loss: 0.0045\n",
            "Epoch 25/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "/content/app.py:132: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "2021-10-25 02:44:25.264 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\", line 2898, in get_loc\n",
            "    return self._engine.get_loc(casted_key)\n",
            "  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1675, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1683, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "KeyError: 'Close'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/script_runner.py\", line 354, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 133, in <module>\n",
            "    plt.plot(train_data[\"Close\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\", line 2906, in __getitem__\n",
            "    indexer = self.columns.get_loc(key)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\", line 2900, in get_loc\n",
            "    raise KeyError(key) from err\n",
            "KeyError: 'Close'\n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/25\n",
            "7/7 - 3s - loss: 0.2072\n",
            "Epoch 2/25\n",
            "7/7 - 0s - loss: 0.0301\n",
            "Epoch 3/25\n",
            "7/7 - 0s - loss: 0.0113\n",
            "Epoch 4/25\n",
            "7/7 - 0s - loss: 0.0156\n",
            "Epoch 5/25\n",
            "7/7 - 0s - loss: 0.0073\n",
            "Epoch 6/25\n",
            "7/7 - 0s - loss: 0.0080\n",
            "Epoch 7/25\n",
            "7/7 - 0s - loss: 0.0064\n",
            "Epoch 8/25\n",
            "7/7 - 0s - loss: 0.0055\n",
            "Epoch 9/25\n",
            "7/7 - 0s - loss: 0.0051\n",
            "Epoch 10/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 11/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 12/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 13/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 14/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 15/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 16/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 17/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 18/25\n",
            "7/7 - 0s - loss: 0.0045\n",
            "Epoch 19/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 20/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 21/25\n",
            "7/7 - 0s - loss: 0.0045\n",
            "Epoch 22/25\n",
            "7/7 - 0s - loss: 0.0045\n",
            "Epoch 23/25\n",
            "7/7 - 0s - loss: 0.0045\n",
            "Epoch 24/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 25/25\n",
            "7/7 - 0s - loss: 0.0048\n",
            "/content/app.py:132: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/25\n",
            "7/7 - 3s - loss: 0.2254\n",
            "Epoch 2/25\n",
            "7/7 - 0s - loss: 0.0310\n",
            "Epoch 3/25\n",
            "7/7 - 0s - loss: 0.0117\n",
            "Epoch 4/25\n",
            "7/7 - 0s - loss: 0.0154\n",
            "Epoch 5/25\n",
            "7/7 - 0s - loss: 0.0077\n",
            "Epoch 6/25\n",
            "7/7 - 0s - loss: 0.0078\n",
            "Epoch 7/25\n",
            "7/7 - 0s - loss: 0.0066\n",
            "Epoch 8/25\n",
            "7/7 - 0s - loss: 0.0052\n",
            "Epoch 9/25\n",
            "7/7 - 0s - loss: 0.0055\n",
            "Epoch 10/25\n",
            "7/7 - 0s - loss: 0.0050\n",
            "Epoch 11/25\n",
            "7/7 - 0s - loss: 0.0049\n",
            "Epoch 12/25\n",
            "7/7 - 0s - loss: 0.0048\n",
            "Epoch 13/25\n",
            "7/7 - 0s - loss: 0.0048\n",
            "Epoch 14/25\n",
            "7/7 - 0s - loss: 0.0049\n",
            "Epoch 15/25\n",
            "7/7 - 0s - loss: 0.0049\n",
            "Epoch 16/25\n",
            "7/7 - 0s - loss: 0.0049\n",
            "Epoch 17/25\n",
            "7/7 - 0s - loss: 0.0049\n",
            "Epoch 18/25\n",
            "7/7 - 0s - loss: 0.0048\n",
            "Epoch 19/25\n",
            "7/7 - 0s - loss: 0.0049\n",
            "Epoch 20/25\n",
            "7/7 - 0s - loss: 0.0048\n",
            "Epoch 21/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 22/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 23/25\n",
            "7/7 - 0s - loss: 0.0049\n",
            "Epoch 24/25\n",
            "7/7 - 0s - loss: 0.0047\n",
            "Epoch 25/25\n",
            "7/7 - 0s - loss: 0.0048\n",
            "/content/app.py:132: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-25 02:46:56.535 INFO    pyngrok.process.ngrok: t=2021-10-25T02:46:56+0000 lvl=info msg=\"join connections\" obj=join id=031aa904734f l=127.0.0.1:80 r=122.177.74.239:25684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "\n",
            "1 Failed download:\n",
            "- APPLE: No data found, symbol may be delisted\n",
            "2021-10-25 02:47:48.158 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/script_runner.py\", line 354, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 89, in <module>\n",
            "    scaled_data=scaler.fit_transform(new_dataset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 571, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 339, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 373, in partial_fit\n",
            "    force_all_finite=\"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 586, in check_array\n",
            "    context))\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "\n",
            "1 Failed download:\n",
            "- APPL: No data found for this date range, symbol may be delisted\n",
            "2021-10-25 02:47:58.394 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/script_runner.py\", line 354, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 89, in <module>\n",
            "    scaled_data=scaler.fit_transform(new_dataset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 571, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 339, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 373, in partial_fit\n",
            "    force_all_finite=\"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 586, in check_array\n",
            "    context))\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "\n",
            "1 Failed download:\n",
            "- APPL: No data found for this date range, symbol may be delisted\n",
            "2021-10-25 02:48:28.442 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/script_runner.py\", line 354, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 89, in <module>\n",
            "    scaled_data=scaler.fit_transform(new_dataset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 571, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 339, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 373, in partial_fit\n",
            "    force_all_finite=\"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 586, in check_array\n",
            "    context))\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "\n",
            "1 Failed download:\n",
            "- APPL: No data found for this date range, symbol may be delisted\n",
            "2021-10-25 02:48:31.396 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/script_runner.py\", line 354, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 89, in <module>\n",
            "    scaled_data=scaler.fit_transform(new_dataset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 571, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 339, in fit\n",
            "    return self.partial_fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\", line 373, in partial_fit\n",
            "    force_all_finite=\"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 586, in check_array\n",
            "    context))\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/25\n",
            "7/7 - 3s - loss: 0.0761\n",
            "Epoch 2/25\n",
            "7/7 - 0s - loss: 0.0120\n",
            "Epoch 3/25\n",
            "7/7 - 0s - loss: 0.0106\n",
            "Epoch 4/25\n",
            "7/7 - 0s - loss: 0.0038\n",
            "Epoch 5/25\n",
            "7/7 - 0s - loss: 0.0035\n",
            "Epoch 6/25\n",
            "7/7 - 0s - loss: 0.0031\n",
            "Epoch 7/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 8/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 9/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 10/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 11/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 12/25\n",
            "7/7 - 0s - loss: 0.0030\n",
            "Epoch 13/25\n",
            "7/7 - 0s - loss: 0.0030\n",
            "Epoch 14/25\n",
            "7/7 - 0s - loss: 0.0030\n",
            "Epoch 15/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 16/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 17/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 18/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 19/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 20/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 21/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 22/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 23/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 24/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 25/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "2021-10-25 02:48:51.387 5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6b51cc440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "/content/app.py:132: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/25\n",
            "7/7 - 3s - loss: 0.1503\n",
            "Epoch 2/25\n",
            "7/7 - 0s - loss: 0.0298\n",
            "Epoch 3/25\n",
            "7/7 - 0s - loss: 0.0125\n",
            "Epoch 4/25\n",
            "7/7 - 0s - loss: 0.0059\n",
            "Epoch 5/25\n",
            "7/7 - 0s - loss: 0.0061\n",
            "Epoch 6/25\n",
            "7/7 - 0s - loss: 0.0035\n",
            "Epoch 7/25\n",
            "7/7 - 0s - loss: 0.0033\n",
            "Epoch 8/25\n",
            "7/7 - 0s - loss: 0.0030\n",
            "Epoch 9/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 10/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 11/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 12/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 13/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 14/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 15/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 16/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 17/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 18/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 19/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 20/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 21/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 22/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 23/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 24/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 25/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "2021-10-25 02:51:00.307 6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6b69fd830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "/content/app.py:132: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/25\n",
            "65/65 - 6s - loss: 0.0134\n",
            "Epoch 2/25\n",
            "65/65 - 3s - loss: 0.0016\n",
            "Epoch 3/25\n",
            "65/65 - 3s - loss: 0.0016\n",
            "Epoch 4/25\n",
            "65/65 - 3s - loss: 0.0013\n",
            "Epoch 5/25\n",
            "65/65 - 3s - loss: 0.0012\n",
            "Epoch 6/25\n",
            "65/65 - 3s - loss: 0.0012\n",
            "Epoch 7/25\n",
            "65/65 - 3s - loss: 0.0010\n",
            "Epoch 8/25\n",
            "65/65 - 3s - loss: 0.0011\n",
            "Epoch 9/25\n",
            "65/65 - 3s - loss: 8.6637e-04\n",
            "Epoch 10/25\n",
            "65/65 - 3s - loss: 7.9180e-04\n",
            "Epoch 11/25\n",
            "65/65 - 3s - loss: 7.6770e-04\n",
            "Epoch 12/25\n",
            "65/65 - 3s - loss: 6.8071e-04\n",
            "Epoch 13/25\n",
            "65/65 - 3s - loss: 6.6493e-04\n",
            "Epoch 14/25\n",
            "65/65 - 3s - loss: 6.2840e-04\n",
            "Epoch 15/25\n",
            "65/65 - 3s - loss: 6.7119e-04\n",
            "Epoch 16/25\n",
            "65/65 - 3s - loss: 5.8625e-04\n",
            "Epoch 17/25\n",
            "65/65 - 3s - loss: 5.4185e-04\n",
            "Epoch 18/25\n",
            "65/65 - 3s - loss: 4.9896e-04\n",
            "Epoch 19/25\n",
            "65/65 - 3s - loss: 5.1725e-04\n",
            "Epoch 20/25\n",
            "65/65 - 3s - loss: 4.8475e-04\n",
            "Epoch 21/25\n",
            "65/65 - 3s - loss: 4.5765e-04\n",
            "Epoch 22/25\n",
            "65/65 - 3s - loss: 4.3615e-04\n",
            "Epoch 23/25\n",
            "65/65 - 3s - loss: 4.7479e-04\n",
            "Epoch 24/25\n",
            "65/65 - 3s - loss: 4.5346e-04\n",
            "Epoch 25/25\n",
            "65/65 - 3s - loss: 4.1797e-04\n",
            "/content/app.py:132: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/25\n",
            "7/7 - 3s - loss: 0.1276\n",
            "Epoch 2/25\n",
            "7/7 - 0s - loss: 0.0219\n",
            "Epoch 3/25\n",
            "7/7 - 0s - loss: 0.0091\n",
            "Epoch 4/25\n",
            "7/7 - 0s - loss: 0.0042\n",
            "Epoch 5/25\n",
            "7/7 - 0s - loss: 0.0046\n",
            "Epoch 6/25\n",
            "7/7 - 0s - loss: 0.0033\n",
            "Epoch 7/25\n",
            "7/7 - 0s - loss: 0.0030\n",
            "Epoch 8/25\n",
            "7/7 - 0s - loss: 0.0029\n",
            "Epoch 9/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 10/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 11/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 12/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 13/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 14/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 15/25\n",
            "7/7 - 0s - loss: 0.0029\n",
            "Epoch 16/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 17/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 18/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 19/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 20/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 21/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 22/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 23/25\n",
            "7/7 - 0s - loss: 0.0029\n",
            "Epoch 24/25\n",
            "7/7 - 0s - loss: 0.0026\n",
            "Epoch 25/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "/content/app.py:132: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Epoch 1/25\n",
            "7/7 - 3s - loss: 0.1226\n",
            "Epoch 2/25\n",
            "7/7 - 0s - loss: 0.0192\n",
            "Epoch 3/25\n",
            "7/7 - 0s - loss: 0.0071\n",
            "Epoch 4/25\n",
            "7/7 - 0s - loss: 0.0040\n",
            "Epoch 5/25\n",
            "7/7 - 0s - loss: 0.0042\n",
            "Epoch 6/25\n",
            "7/7 - 0s - loss: 0.0030\n",
            "Epoch 7/25\n",
            "7/7 - 0s - loss: 0.0031\n",
            "Epoch 8/25\n",
            "7/7 - 0s - loss: 0.0031\n",
            "Epoch 9/25\n",
            "7/7 - 0s - loss: 0.0029\n",
            "Epoch 10/25\n",
            "7/7 - 0s - loss: 0.0030\n",
            "Epoch 11/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 12/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 13/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 14/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 15/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 16/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 17/25\n",
            "7/7 - 0s - loss: 0.0028\n",
            "Epoch 18/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 19/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 20/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 21/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 22/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 23/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 24/25\n",
            "7/7 - 0s - loss: 0.0027\n",
            "Epoch 25/25\n",
            "7/7 - 0s - loss: 0.0029\n",
            "/content/app.py:132: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        }
      ]
    }
  ]
}